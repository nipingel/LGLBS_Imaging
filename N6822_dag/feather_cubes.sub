# combine_images.sub
# script to base submission of LGLBS imaging jobs
#
# Specify the HTCondor Universe (vanilla is the default and is used
#  for almost all jobs) and your desired name of the HTCondor log file,
#  which is where HTCondor will describe what steps it takes to run 
#  your job. Wherever you see $(Cluster), HTCondor will insert the 
#  queue number assigned to this set of jobs at the time of submission.
universe = docker
docker_image = nipingel/casa:latest
log = run_feather.log
#
# Specify your executable (single binary or a script that runs several
#  commands), arguments, and a files for HTCondor to store standard
#  output (or "screen output").
#  $(Process) will be a integer number for each job, starting with "0"
#  and increasing for the relevant number of jobs.

## imaging ()
executable = feather_cubes.py

rc_name="NGC6822" sdcube="N6822_GBT_Jy.eq.nostokes.fits" interfcube=" NGC6822_A+B+C+D_HI_0p4kms.fits" outpath="/projects/vla-processing/images/NGC6822/NGC6822_A+B+C+D_HI_0p4kms.feather.fits" galaxy="ngc6822"

arguments = $(src_name) $(sdcube) $(interfcube) $(outpath) $(galaxy)
output = run_feather.out
error = run_feather.err

# Specify that HTCondor should transfer files to and from the
#  computer where each job runs. The last of these lines *would* be
#  used if there were any other files needed for the executable to use.
Requirements=(Target.HasCHTCStaging == true) && (OpSysMajorVer =?= 8)
+HasCHTCStaging=true

# Tell HTCondor what amount of compute resources
#  each job will need on the computer where it runs.
transfer_input_files = combine_images.sh, combine_images.py
request_cpus = 1
request_memory = 100GB
request_disk = 10GB
#
# Tell HTCondor to run 1 instances of our job:
queue 1